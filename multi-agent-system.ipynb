{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beaafe0-7d98-4bc7-9ebb-e49fc081d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AgentType(Enum):\n",
    "    MAIN = \"main\"\n",
    "    FILTER = \"filter\"\n",
    "    ACTION = \"action\"\n",
    "\n",
    "@dataclass\n",
    "class ChatMessage:\n",
    "    role: str  # 'user', 'assistant', 'system'\n",
    "    content: str\n",
    "    agent_type: Optional[AgentType] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "\n",
    "@dataclass\n",
    "class HandoffDecision:\n",
    "    should_handoff: bool\n",
    "    target_agent: Optional[AgentType] = None\n",
    "    reason: str = \"\"\n",
    "    continue_conversation: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378100a2-c311-436e-87f4-5c0a8c5e3bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ee7cf-c861-45fe-8094-3f835088dbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "116ac8a7-8d43-42f4-acd9-411eb778ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationMemory:\n",
    "    \"\"\"Manages conversation history and context across agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages: List[ChatMessage] = []\n",
    "        self.current_agent: AgentType = AgentType.MAIN\n",
    "        self.agent_context: Dict[AgentType, Dict[str, Any]] = {\n",
    "            AgentType.MAIN: {},\n",
    "            AgentType.FILTER: {},\n",
    "            AgentType.ACTION: {}\n",
    "        }\n",
    "        self.handoff_history: List[Tuple[AgentType, AgentType, str]] = []\n",
    "    \n",
    "    def add_message(self, message: ChatMessage):\n",
    "        \"\"\"Add a message to conversation history\"\"\"\n",
    "        self.messages.append(message)\n",
    "        logger.info(f\"Added message from {message.agent_type}: {message.content[:50]}...\")\n",
    "    \n",
    "    def get_recent_messages(self, count: int = 10) -> List[ChatMessage]:\n",
    "        \"\"\"Get recent messages for context\"\"\"\n",
    "        return self.messages[-count:] if len(self.messages) >= count else self.messages\n",
    "    \n",
    "    def get_agent_context(self, agent_type: AgentType) -> Dict[str, Any]:\n",
    "        \"\"\"Get context specific to an agent\"\"\"\n",
    "        return self.agent_context.get(agent_type, {})\n",
    "    \n",
    "    def update_agent_context(self, agent_type: AgentType, context: Dict[str, Any]):\n",
    "        \"\"\"Update agent-specific context\"\"\"\n",
    "        self.agent_context[agent_type].update(context)\n",
    "    \n",
    "    def record_handoff(self, from_agent: AgentType, to_agent: AgentType, reason: str):\n",
    "        \"\"\"Record handoff between agents\"\"\"\n",
    "        self.handoff_history.append((from_agent, to_agent, reason))\n",
    "        self.current_agent = to_agent\n",
    "        logger.info(f\"Handoff: {from_agent.value} -> {to_agent.value} ({reason})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808061f2-5916-44db-a152-2333a8c4e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent(ABC):\n",
    "    \"\"\"Base class for all agents\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_type: AgentType, openai_client:OpenAI):\n",
    "        self.agent_type = agent_type\n",
    "        self.client = openai_client\n",
    "        self.system_prompt = self._get_system_prompt()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_system_prompt(self) -> str:\n",
    "        \"\"\"Get the system prompt for this agent\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_query(self, query: str, memory: ConversationMemory) -> Tuple[str, HandoffDecision]:\n",
    "        \"\"\"Process a query and return response with handoff decision\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _call_openai(self, messages: List[Dict[str, str]], max_tokens: int = 1000) -> str:\n",
    "        \"\"\"Make a call to OpenAI API\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OpenAI API call failed: {e}\")\n",
    "            return f\"Error: Unable to process request - {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f884574-3e4b-476c-bc98-34949dc4adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainAgent(BaseAgent):\n",
    "    \"\"\"Main orchestrator agent that manages handoffs\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client: OpenAI):\n",
    "        super().__init__(AgentType.MAIN, openai_client)\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are the Main Orchestrator Agent in a multi-agent system. Your responsibilities:\n",
    "\n",
    "1. ANALYZE user queries to determine which specialized agent should handle them\n",
    "2. DECIDE handoffs between Filter Agent (for filtering/search queries) and Action Agent (for actions like add_outreach, get_csv, add_marketo)\n",
    "3. MAINTAIN conversation context and flow\n",
    "4. HANDLE requests to switch between agents mid-conversation\n",
    "\n",
    "Agent Capabilities:\n",
    "- Filter Agent: Handles filtering, searching, querying data, creating filter criteria\n",
    "- Action Agent: Handles actions like add_outreach, get_csv, add_marketo, data manipulation\n",
    "\n",
    "Decision Rules:\n",
    "- If query involves filtering, searching, or querying -> Filter Agent\n",
    "- If query involves actions or data manipulation -> Action Agent  \n",
    "- If query asks to switch agents or is ambiguous -> Stay with Main Agent for clarification\n",
    "- If query continues previous conversation -> Consider context\n",
    "\n",
    "Respond with JSON format:\n",
    "{\n",
    "    \"handoff_needed\": true/false,\n",
    "    \"target_agent\": \"filter\"/\"action\"/null,\n",
    "    \"reason\": \"explanation\",\n",
    "    \"response\": \"your response to user\"\n",
    "}\"\"\"\n",
    "    \n",
    "    def process_query(self, query: str, memory: ConversationMemory) -> Tuple[str, HandoffDecision]:\n",
    "        \"\"\"Analyze query and decide on handoffs\"\"\"\n",
    "        \n",
    "        # Build context from recent messages\n",
    "        recent_messages = memory.get_recent_messages(5)\n",
    "        context = \"\\n\".join([f\"{msg.role}: {msg.content}\" for msg in recent_messages[-3:]])\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                                Current context: {context}\n",
    "                                \n",
    "                                Current agent: {memory.current_agent.value}\n",
    "                                \n",
    "                                User query: {query}\n",
    "                                \n",
    "                                Analyze this query and decide if handoff is needed.\"\"\"}\n",
    "                                        ]\n",
    "                                        \n",
    "        response = self._call_openai(messages)\n",
    "        \n",
    "        try:\n",
    "            # Try to parse JSON response\n",
    "            result = json.loads(response)\n",
    "            handoff_decision = HandoffDecision(\n",
    "                should_handoff=result.get(\"handoff_needed\", False),\n",
    "                target_agent=AgentType(result[\"target_agent\"]) if result.get(\"target_agent\") else None,\n",
    "                reason=result.get(\"reason\", \"\")\n",
    "            )\n",
    "            return result.get(\"response\", response), handoff_decision\n",
    "        except (json.JSONDecodeError, KeyError, ValueError):\n",
    "            # Fallback if JSON parsing fails\n",
    "            return response, HandoffDecision(should_handoff=False, reason=\"Failed to parse decision\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3aa887-fa3d-461c-9091-1d7ff2053cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in filtering and search operations\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client: OpenAI):\n",
    "        super().__init__(AgentType.FILTER, openai_client)\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are the Filter Agent specialized in creating filter queries and handling search operations.\n",
    "\n",
    "                Your capabilities:\n",
    "                - Create filter queries based on user requirements\n",
    "                - Handle search and filtering requests\n",
    "                - Process data querying needs\n",
    "                - Generate SQL-like filters\n",
    "                - Handle complex search criteria\n",
    "                \n",
    "                For each response, also analyze if the user's query requires:\n",
    "                1. Continuation with filtering/search tasks -> stay with Filter Agent\n",
    "                2. Action operations (add_outreach, get_csv, add_marketo) -> handoff to Action Agent\n",
    "                3. General questions or agent switching -> handoff to Main Agent\n",
    "                \n",
    "                Respond with JSON format:\n",
    "                {\n",
    "                    \"filter_response\": \"your detailed filter response\",\n",
    "                    \"handoff_needed\": true/false,\n",
    "                    \"target_agent\": \"main\"/\"action\"/null,\n",
    "                    \"reason\": \"explanation if handoff needed\"\n",
    "                }\"\"\"\n",
    "    \n",
    "    def process_query(self, query: str, memory: ConversationMemory) -> Tuple[str, HandoffDecision]:\n",
    "        \"\"\"Process filtering queries\"\"\"\n",
    "        \n",
    "        # Get filter-specific context\n",
    "        filter_context = memory.get_agent_context(AgentType.FILTER)\n",
    "        recent_messages = memory.get_recent_messages(3)\n",
    "        context = \"\\n\".join([f\"{msg.role}: {msg.content}\" for msg in recent_messages])\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Previous context: {context}\n",
    "            Filter context: {filter_context}\n",
    "            \n",
    "            User query: {query}\n",
    "            \n",
    "            Process this filtering request and determine if handoff is needed.\"\"\"}\n",
    "                    ]\n",
    "        \n",
    "        response = self._call_openai(messages)\n",
    "        \n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            \n",
    "            # Update filter context with query results\n",
    "            memory.update_agent_context(AgentType.FILTER, {\n",
    "                \"last_query\": query,\n",
    "                \"last_response\": result.get(\"filter_response\", \"\")\n",
    "            })\n",
    "            \n",
    "            handoff_decision = HandoffDecision(\n",
    "                should_handoff=result.get(\"handoff_needed\", False),\n",
    "                target_agent=AgentType(result[\"target_agent\"]) if result.get(\"target_agent\") else None,\n",
    "                reason=result.get(\"reason\", \"\")\n",
    "            )\n",
    "            \n",
    "            return result.get(\"filter_response\", response), handoff_decision\n",
    "        except (json.JSONDecodeError, KeyError, ValueError):\n",
    "            return response, HandoffDecision(should_handoff=False, reason=\"Continuing with filter operations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034162bd-4209-4f1c-98a9-8851b9736813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in action operations\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client: OpenAI):\n",
    "        super().__init__(AgentType.ACTION, openai_client)\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are the Action Agent specialized in performing actions like add_outreach, get_csv, add_marketo.\n",
    "\n",
    "                Your capabilities:\n",
    "                - add_outreach: Add outreach campaigns\n",
    "                - get_csv: Retrieve and process CSV data  \n",
    "                - add_marketo: Add Marketo integrations\n",
    "                - Data manipulation and processing actions\n",
    "                - Execute operational tasks\n",
    "                \n",
    "                For each response, analyze if the user's query requires:\n",
    "                1. More action operations -> stay with Action Agent\n",
    "                2. Filtering/search operations -> handoff to Filter Agent\n",
    "                3. General questions or agent switching -> handoff to Main Agent\n",
    "                \n",
    "                Respond with JSON format:\n",
    "                {\n",
    "                    \"action_response\": \"your detailed action response with results\",\n",
    "                    \"actions_performed\": [\"list\", \"of\", \"actions\"],\n",
    "                    \"handoff_needed\": true/false,\n",
    "                    \"target_agent\": \"main\"/\"filter\"/null,\n",
    "                    \"reason\": \"explanation if handoff needed\"\n",
    "                }\"\"\"\n",
    "    \n",
    "    def process_query(self, query: str, memory: ConversationMemory) -> Tuple[str, HandoffDecision]:\n",
    "        \"\"\"Process action queries\"\"\"\n",
    "        \n",
    "        # Get action-specific context\n",
    "        action_context = memory.get_agent_context(AgentType.ACTION)\n",
    "        recent_messages = memory.get_recent_messages(3)\n",
    "        context = \"\\n\".join([f\"{msg.role}: {msg.content}\" for msg in recent_messages])\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                Previous context: {context}\n",
    "                Action context: {action_context}\n",
    "                \n",
    "                User query: {query}\n",
    "                \n",
    "                Process this action request and determine if handoff is needed.\"\"\"}\n",
    "                        ]\n",
    "                        \n",
    "        response = self._call_openai(messages)\n",
    "        \n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            \n",
    "            # Update action context\n",
    "            memory.update_agent_context(AgentType.ACTION, {\n",
    "                \"last_query\": query,\n",
    "                \"last_actions\": result.get(\"actions_performed\", []),\n",
    "                \"last_response\": result.get(\"action_response\", \"\")\n",
    "            })\n",
    "            \n",
    "            handoff_decision = HandoffDecision(\n",
    "                should_handoff=result.get(\"handoff_needed\", False),\n",
    "                target_agent=AgentType(result[\"target_agent\"]) if result.get(\"target_agent\") else None,\n",
    "                reason=result.get(\"reason\", \"\")\n",
    "            )\n",
    "            \n",
    "            return result.get(\"action_response\", response), handoff_decision\n",
    "        except (json.JSONDecodeError, KeyError, ValueError):\n",
    "            return response, HandoffDecision(should_handoff=False, reason=\"Continuing with action operations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba7e58d-a559-45ed-b51b-d81b88ffe504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentSystem:\n",
    "    \"\"\"Main multi-agent system orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str):\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.memory = ConversationMemory()\n",
    "        \n",
    "        # Initialize agents\n",
    "        self.agents = {\n",
    "            AgentType.MAIN: MainAgent(self.client),\n",
    "            AgentType.FILTER: FilterAgent(self.client),\n",
    "            AgentType.ACTION: ActionAgent(self.client)\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Multi-agent system initialized\")\n",
    "    \n",
    "    def process_query(self, user_query: str) -> str:\n",
    "        \"\"\"Process user query through the multi-agent system\"\"\"\n",
    "        \n",
    "        # Add user message to memory\n",
    "        user_message = ChatMessage(role=\"user\", content=user_query)\n",
    "        self.memory.add_message(user_message)\n",
    "        \n",
    "        current_agent = self.agents[self.memory.current_agent]\n",
    "        logger.info(f\"Processing query with {current_agent.agent_type.value} agent\")\n",
    "        \n",
    "        try:\n",
    "            # Process query with current agent\n",
    "            response, handoff_decision = current_agent.process_query(user_query, self.memory)\n",
    "            \n",
    "            # Add agent response to memory\n",
    "            agent_message = ChatMessage(\n",
    "                role=\"assistant\", \n",
    "                content=response,\n",
    "                agent_type=current_agent.agent_type\n",
    "            )\n",
    "            self.memory.add_message(agent_message)\n",
    "            \n",
    "            # Handle handoff if needed\n",
    "            if handoff_decision.should_handoff and handoff_decision.target_agent:\n",
    "                self.memory.record_handoff(\n",
    "                    current_agent.agent_type, \n",
    "                    handoff_decision.target_agent, \n",
    "                    handoff_decision.reason\n",
    "                )\n",
    "                \n",
    "                # If handoff to a different agent, process with new agent\n",
    "                if handoff_decision.target_agent != current_agent.agent_type:\n",
    "                    next_agent = self.agents[handoff_decision.target_agent]\n",
    "                    next_response, _ = next_agent.process_query(user_query, self.memory)\n",
    "                    \n",
    "                    # Add the new agent's response\n",
    "                    next_message = ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=next_response,\n",
    "                        agent_type=handoff_decision.target_agent\n",
    "                    )\n",
    "                    self.memory.add_message(next_message)\n",
    "                    \n",
    "                    response = f\"{response}\\n\\n[Handed off to {handoff_decision.target_agent.value} agent]\\n\\n{next_response}\"\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "            return f\"I apologize, but I encountered an error processing your request: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get formatted conversation history\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"role\": msg.role,\n",
    "                \"content\": msg.content,\n",
    "                \"agent\": msg.agent_type.value if msg.agent_type else None\n",
    "            }\n",
    "            for msg in self.memory.messages\n",
    "        ]\n",
    "    \n",
    "    def get_current_agent(self) -> str:\n",
    "        \"\"\"Get current active agent\"\"\"\n",
    "        return self.memory.current_agent.value\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset the conversation and memory\"\"\"\n",
    "        self.memory = ConversationMemory()\n",
    "        logger.info(\"Conversation reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4789d0fa-7a1f-49c1-8588-50375f2a02f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Multi-agent system initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Agent System Started!\n",
      "Available commands:\n",
      "- Type your queries naturally\n",
      "- Type 'history' to see conversation history\n",
      "- Type 'current' to see current agent\n",
      "- Type 'reset' to reset conversation\n",
      "- Type 'quit' to exit\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added message from None: hello...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": false,\n",
      "    \"target...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: ```json\n",
      "{\n",
      "    \"handoff_needed\": false,\n",
      "    \"target_agent\": null,\n",
      "    \"reason\": \"The user is simply greeting, no specific task or query has been mentioned.\",\n",
      "    \"response\": \"Hello! How can I assist you today? If you have any tasks or queries, feel free to let me know.\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Filter contacts by name containing 'John\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added message from None: Filter contacts by name containing 'John...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_agent\": \"filter\",\n",
      "    \"reason\": \"The user is requesting to filter contacts by name, which involves searching and querying data.\",\n",
      "    \"response\": \"I will hand you over to the Filter Agent to assist you with filtering contacts by names containing 'John'.\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Filter contacts by name containing 'John\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Added message from None: Filter contacts by name containing 'John...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_agent\": \"filter\",\n",
      "    \"reason\": \"The user is requesting to filter contacts by name, which involves searching and querying data.\",\n",
      "    \"response\": \"I will hand you over to the Filter Agent to assist you with filtering contacts by names containing 'John'.\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize the system\n",
    "    openai_api_key = \"your-openai-api-key-here\"  # Replace with your actual API key\n",
    "    system = MultiAgentSystem(openai_api_key=None)\n",
    "    \n",
    "    print(\"Multi-Agent System Started!\")\n",
    "    print(\"Available commands:\")\n",
    "    print(\"- Type your queries naturally\")\n",
    "    print(\"- Type 'history' to see conversation history\")\n",
    "    print(\"- Type 'current' to see current agent\")\n",
    "    print(\"- Type 'reset' to reset conversation\")\n",
    "    print(\"- Type 'quit' to exit\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        elif user_input.lower() == 'history':\n",
    "            history = system.get_conversation_history()\n",
    "            for entry in history[-5:]:  # Show last 5 entries\n",
    "                print(f\"{entry['role']} ({entry['agent']}): {entry['content'][:100]}...\")\n",
    "        elif user_input.lower() == 'current':\n",
    "            print(f\"Current agent: {system.get_current_agent()}\")\n",
    "        elif user_input.lower() == 'reset':\n",
    "            system.reset_conversation()\n",
    "            print(\"Conversation reset!\")\n",
    "        elif user_input:\n",
    "            response = system.process_query(user_input)\n",
    "            print(f\"\\nSystem: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bb394a-b637-418a-af7c-44b34393f3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Multi-agent system initialized\n",
      "INFO:__main__:Added message from None: Filter customers by location and age...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n",
      "INFO:__main__:Added message from None: Add outreach campaign for new leads...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n",
      "INFO:__main__:Added message from None: Now get the CSV data for those results...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n",
      "INFO:__main__:Added message from None: Filter that data by purchase history...\n",
      "INFO:__main__:Processing query with main agent\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Added message from AgentType.MAIN: ```json\n",
      "{\n",
      "    \"handoff_needed\": true,\n",
      "    \"target_...\n",
      "INFO:__main__:Conversation reset\n"
     ]
    }
   ],
   "source": [
    "# Initialize system\n",
    "system = MultiAgentSystem(None)\n",
    "\n",
    "# Example queries that would trigger different agents:\n",
    "system.process_query(\"Filter customers by location and age\")  # -> Filter Agent\n",
    "system.process_query(\"Add outreach campaign for new leads\")  # -> Action Agent  \n",
    "system.process_query(\"Now get the CSV data for those results\")  # -> Action Agent\n",
    "system.process_query(\"Filter that data by purchase history\")  # -> Filter Agent\n",
    "\n",
    "system.reset_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd505fc-5051-408f-a721-237187b791b9",
   "metadata": {},
   "source": [
    "# Generic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5e1ffd-84a8-4e34-bb4d-f7935fbef1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Agent System initialized!\n",
      "Available agents:\n",
      "- Main Orchestrator Agent (main_agent)\n",
      "- Code Assistant (code_assistant)\n",
      "- Data Analyst (data_analyst)\n",
      "- Writing Assistant (writing_assistant)\n",
      "\n",
      "--- Query: Help me write a Python function to sort a list ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Code Assistant\n",
      "Response: Certainly! Here is a simple Python function that sorts a list using the built-in `sorted()` function:\n",
      "\n",
      "```python\n",
      "\n",
      "def sort_list(input_list):\n",
      "    return sorted(input_list)\n",
      "\n",
      "# Example usage:\n",
      "my_list = [5, 2, 9, 1, 5, 6]\n",
      "sorted_list = sort_list(my_list)\n",
      "print(sorted_list)  # Output: [1, 2, 5, 5, 6, 9]\n",
      "```\n",
      "\n",
      "This function takes a list as input and returns a new list that is sorted in ascending order. The `sorted()` function is efficient and handles sorting internally. If you need to sort the list in place, you can use the `sort()` method of the list object itself.\n",
      "Handoffs: 1\n",
      "\n",
      "--- Query: I need help analyzing my sales data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Data Analyst\n",
      "Response: I'd be happy to help you analyze your sales data! To get started, could you provide more details about the data you have? For example, the type of data (e.g., sales figures, customer demographics), the format (e.g., CSV, Excel), and any specific questions or insights you are looking to gain from the analysis.\n",
      "Handoffs: 1\n",
      "\n",
      "--- Query: Can you help me write a creative story? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Writing Assistant\n",
      "Response: Of course! I'd love to help you write a creative story. To get started, could you provide some details or themes you'd like to explore? For example, do you have a particular genre in mind, such as fantasy, mystery, or romance? Or perhaps a setting or a character you want to develop? Let me know, and we can start crafting your story together!\n",
      "Handoffs: 1\n",
      "\n",
      "--- Query: What's the weather like today? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Main Orchestrator Agent\n",
      "Response: I'm unable to provide real-time weather updates. However, you can check the current weather by using a weather website or app like Weather.com or a weather service API if you're looking to integrate weather data into a project.\n",
      "Handoffs: 0\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "class AgentType(Enum):\n",
    "    MAIN = \"main\"\n",
    "    SPECIALIZED = \"specialized\"\n",
    "\n",
    "class HandoffDecision(Enum):\n",
    "    CONTINUE = \"continue\"\n",
    "    HANDOFF_TO_MAIN = \"handoff_to_main\"\n",
    "    HANDOFF_TO_AGENT = \"handoff_to_agent\"\n",
    "    DIRECT_RESPONSE = \"direct_response\"\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "    role: str\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    agent_id: Optional[str] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class AgentMemory:\n",
    "    agent_interactions: Dict[str, List[Message]] = field(default_factory=dict)\n",
    "    agent_capabilities: Dict[str, List[str]] = field(default_factory=dict)\n",
    "    context_history: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    current_agent: Optional[str] = None\n",
    "    handoff_count: int = 0\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    def __init__(self, agent_id: str, name: str, description: str, capabilities: List[str]):\n",
    "        self.agent_id = agent_id\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.capabilities = capabilities\n",
    "        self.client = openai.OpenAI()  # Initialize OpenAI client\n",
    "        \n",
    "    @abstractmethod\n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        pass\n",
    "\n",
    "class MainAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"main_agent\",\n",
    "            name=\"Main Orchestrator Agent\",\n",
    "            description=\"Main agent responsible for routing queries to appropriate specialized agents\",\n",
    "            capabilities=[\"routing\", \"orchestration\", \"context_management\", \"handoff_decision\"]\n",
    "        )\n",
    "        \n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        \"\"\"Process query and decide on agent routing\"\"\"\n",
    "        \n",
    "        # Create system prompt for main agent\n",
    "        system_prompt = f\"\"\"\n",
    "        You are the Main Orchestrator Agent in a multi-agent system. Your responsibilities:\n",
    "        1. Analyze user queries to determine which specialized agent should handle them\n",
    "        2. Maintain context across agent handoffs\n",
    "        3. Decide when to route queries to specific agents\n",
    "        4. Handle agent-to-agent communication\n",
    "        \n",
    "        Available agents and their capabilities:\n",
    "        {self._get_available_agents_info()}\n",
    "        \n",
    "        Current context: {len(context)} previous messages\n",
    "        \n",
    "        For the user query, provide a JSON response with:\n",
    "        - \"target_agent\": agent_id to route to (or \"main_agent\" to handle yourself)\n",
    "        - \"reasoning\": explanation of routing decision\n",
    "        - \"context_summary\": brief summary of relevant context\n",
    "        - \"response\": your response if handling the query yourself\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare context for LLM\n",
    "        context_messages = []\n",
    "        for msg in context[-10:]:  # Last 10 messages for context\n",
    "            context_messages.append({\n",
    "                \"role\": msg.role,\n",
    "                \"content\": f\"[{msg.agent_id}] {msg.content}\" if msg.agent_id else msg.content\n",
    "            })\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *context_messages,\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.3,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"target_agent\": \"main_agent\",\n",
    "                \"reasoning\": f\"Error in processing: {str(e)}\",\n",
    "                \"context_summary\": \"Error occurred\",\n",
    "                \"response\": \"I encountered an error processing your request. Please try again.\"\n",
    "            }\n",
    "    \n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        \"\"\"Main agent always processes queries first\"\"\"\n",
    "        return HandoffDecision.CONTINUE, None\n",
    "    \n",
    "    def _get_available_agents_info(self) -> str:\n",
    "        \"\"\"Get information about available agents\"\"\"\n",
    "        # This would be populated by the MultiAgentSystem\n",
    "        return \"This will be populated by the system with available agents\"\n",
    "\n",
    "class SpecializedAgent(BaseAgent):\n",
    "    def __init__(self, agent_id: str, name: str, description: str, capabilities: List[str], \n",
    "                 specialized_prompt: str = \"\"):\n",
    "        super().__init__(agent_id, name, description, capabilities)\n",
    "        self.specialized_prompt = specialized_prompt\n",
    "        \n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        \"\"\"Process query with specialized knowledge\"\"\"\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        You are {self.name}: {self.description}\n",
    "        \n",
    "        Your capabilities: {', '.join(self.capabilities)}\n",
    "        \n",
    "        {self.specialized_prompt}\n",
    "        \n",
    "        Important: If the user's query is outside your expertise or they're asking for a different type of agent,\n",
    "        indicate that you should handoff back to the main agent.\n",
    "        \n",
    "        Provide a JSON response with:\n",
    "        - \"response\": your response to the user\n",
    "        - \"confidence\": confidence level (0-1) in handling this query\n",
    "        - \"should_handoff\": boolean indicating if you should handoff\n",
    "        - \"handoff_reason\": reason for handoff if applicable\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare context\n",
    "        context_messages = []\n",
    "        for msg in context[-5:]:  # Last 5 messages for context\n",
    "            context_messages.append({\n",
    "                \"role\": msg.role,\n",
    "                \"content\": msg.content\n",
    "            })\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *context_messages,\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.5,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"response\": f\"I encountered an error processing your request: {str(e)}\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"should_handoff\": True,\n",
    "                \"handoff_reason\": \"Error occurred\"\n",
    "            }\n",
    "    \n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        \"\"\"Determine if specialized agent should handoff\"\"\"\n",
    "        result = self.process_query(query, context)\n",
    "        \n",
    "        if result.get(\"should_handoff\", False):\n",
    "            return HandoffDecision.HANDOFF_TO_MAIN, \"main_agent\"\n",
    "        elif result.get(\"confidence\", 0) < 0.3:\n",
    "            return HandoffDecision.HANDOFF_TO_MAIN, \"main_agent\"\n",
    "        else:\n",
    "            return HandoffDecision.DIRECT_RESPONSE, None\n",
    "\n",
    "class MultiAgentSystem:\n",
    "    def __init__(self, openai_api_key: str):\n",
    "        \"\"\"Initialize the multi-agent system\"\"\"\n",
    "        openai.api_key = openai_api_key\n",
    "        \n",
    "        self.agents: Dict[str, BaseAgent] = {}\n",
    "        self.memory = AgentMemory()\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Initialize main agent\n",
    "        self.main_agent = MainAgent()\n",
    "        self.agents[self.main_agent.agent_id] = self.main_agent\n",
    "        self.memory.current_agent = self.main_agent.agent_id\n",
    "        \n",
    "        # Update main agent with system reference\n",
    "        self.main_agent._get_available_agents_info = self._get_agents_info\n",
    "    \n",
    "    def add_agent(self, agent: BaseAgent) -> None:\n",
    "        \"\"\"Add a specialized agent to the system\"\"\"\n",
    "        self.agents[agent.agent_id] = agent\n",
    "        self.memory.agent_capabilities[agent.agent_id] = agent.capabilities\n",
    "        \n",
    "    def _get_agents_info(self) -> str:\n",
    "        \"\"\"Get formatted information about all available agents\"\"\"\n",
    "        info = []\n",
    "        for agent_id, agent in self.agents.items():\n",
    "            if agent_id != \"main_agent\":\n",
    "                info.append(f\"- {agent.name} ({agent_id}): {agent.description}\")\n",
    "                info.append(f\"  Capabilities: {', '.join(agent.capabilities)}\")\n",
    "        return \"\\n\".join(info)\n",
    "    \n",
    "    def process_user_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process user query through the multi-agent system\"\"\"\n",
    "        \n",
    "        # Add user message to memory\n",
    "        user_message = Message(content=query, role=\"user\")\n",
    "        self._add_message_to_memory(user_message)\n",
    "        \n",
    "        # Get current context\n",
    "        context = self._get_context_messages()\n",
    "        \n",
    "        # Start with main agent decision\n",
    "        current_agent_id = \"main_agent\"\n",
    "        max_handoffs = 5\n",
    "        handoff_count = 0\n",
    "        \n",
    "        while handoff_count < max_handoffs:\n",
    "            current_agent = self.agents[current_agent_id]\n",
    "            \n",
    "            # Process query with current agent\n",
    "            result = current_agent.process_query(query, context)\n",
    "            \n",
    "            # Check if we need to handoff\n",
    "            handoff_decision, target_agent = current_agent.should_handoff(query, context)\n",
    "            \n",
    "            if handoff_decision == HandoffDecision.DIRECT_RESPONSE:\n",
    "                # Agent can handle the query directly\n",
    "                response_message = Message(\n",
    "                    content=result.get(\"response\", \"No response provided\"),\n",
    "                    role=\"assistant\",\n",
    "                    agent_id=current_agent_id\n",
    "                )\n",
    "                self._add_message_to_memory(response_message)\n",
    "                self.memory.current_agent = current_agent_id\n",
    "                \n",
    "                return {\n",
    "                    \"response\": result.get(\"response\", \"No response provided\"),\n",
    "                    \"agent_used\": current_agent.name,\n",
    "                    \"agent_id\": current_agent_id,\n",
    "                    \"handoff_count\": handoff_count,\n",
    "                    \"confidence\": result.get(\"confidence\", 1.0),\n",
    "                    \"session_id\": self.session_id\n",
    "                }\n",
    "            \n",
    "            elif handoff_decision == HandoffDecision.HANDOFF_TO_MAIN:\n",
    "                # Handoff back to main agent\n",
    "                if current_agent_id == \"main_agent\":\n",
    "                    # Already at main agent, provide response\n",
    "                    response_message = Message(\n",
    "                        content=result.get(\"response\", \"I'm not sure how to help with that.\"),\n",
    "                        role=\"assistant\",\n",
    "                        agent_id=current_agent_id\n",
    "                    )\n",
    "                    self._add_message_to_memory(response_message)\n",
    "                    \n",
    "                    return {\n",
    "                        \"response\": result.get(\"response\", \"I'm not sure how to help with that.\"),\n",
    "                        \"agent_used\": current_agent.name,\n",
    "                        \"agent_id\": current_agent_id,\n",
    "                        \"handoff_count\": handoff_count,\n",
    "                        \"session_id\": self.session_id\n",
    "                    }\n",
    "                else:\n",
    "                    current_agent_id = \"main_agent\"\n",
    "                    handoff_count += 1\n",
    "                    continue\n",
    "            \n",
    "            elif handoff_decision == HandoffDecision.HANDOFF_TO_AGENT:\n",
    "                # Handoff to specific agent\n",
    "                if target_agent and target_agent in self.agents:\n",
    "                    current_agent_id = target_agent\n",
    "                    handoff_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    # Target agent not found, use main agent response\n",
    "                    response_message = Message(\n",
    "                        content=result.get(\"response\", \"Agent not found.\"),\n",
    "                        role=\"assistant\",\n",
    "                        agent_id=current_agent_id\n",
    "                    )\n",
    "                    self._add_message_to_memory(response_message)\n",
    "                    \n",
    "                    return {\n",
    "                        \"response\": result.get(\"response\", \"Agent not found.\"),\n",
    "                        \"agent_used\": current_agent.name,\n",
    "                        \"agent_id\": current_agent_id,\n",
    "                        \"handoff_count\": handoff_count,\n",
    "                        \"session_id\": self.session_id\n",
    "                    }\n",
    "            \n",
    "            # For main agent, check if it wants to route to another agent\n",
    "            if current_agent_id == \"main_agent\":\n",
    "                target_agent_id = result.get(\"target_agent\")\n",
    "                if target_agent_id and target_agent_id != \"main_agent\" and target_agent_id in self.agents:\n",
    "                    current_agent_id = target_agent_id\n",
    "                    handoff_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    # Main agent handles the query itself\n",
    "                    response_message = Message(\n",
    "                        content=result.get(\"response\", \"How can I help you?\"),\n",
    "                        role=\"assistant\",\n",
    "                        agent_id=current_agent_id\n",
    "                    )\n",
    "                    self._add_message_to_memory(response_message)\n",
    "                    \n",
    "                    return {\n",
    "                        \"response\": result.get(\"response\", \"How can I help you?\"),\n",
    "                        \"agent_used\": current_agent.name,\n",
    "                        \"agent_id\": current_agent_id,\n",
    "                        \"handoff_count\": handoff_count,\n",
    "                        \"reasoning\": result.get(\"reasoning\", \"\"),\n",
    "                        \"session_id\": self.session_id\n",
    "                    }\n",
    "        \n",
    "        # Max handoffs reached\n",
    "        return {\n",
    "            \"response\": \"I've reached the maximum number of agent handoffs. Please try rephrasing your question.\",\n",
    "            \"agent_used\": \"System\",\n",
    "            \"agent_id\": \"system\",\n",
    "            \"handoff_count\": handoff_count,\n",
    "            \"session_id\": self.session_id\n",
    "        }\n",
    "    \n",
    "    def _add_message_to_memory(self, message: Message) -> None:\n",
    "        \"\"\"Add message to memory\"\"\"\n",
    "        if message.agent_id:\n",
    "            if message.agent_id not in self.memory.agent_interactions:\n",
    "                self.memory.agent_interactions[message.agent_id] = []\n",
    "            self.memory.agent_interactions[message.agent_id].append(message)\n",
    "        \n",
    "        # Add to context history\n",
    "        self.memory.context_history.append({\n",
    "            \"message\": message,\n",
    "            \"timestamp\": message.timestamp,\n",
    "            \"agent_id\": message.agent_id\n",
    "        })\n",
    "    \n",
    "    def _get_context_messages(self) -> List[Message]:\n",
    "        \"\"\"Get recent context messages\"\"\"\n",
    "        recent_messages = []\n",
    "        for entry in self.memory.context_history[-20:]:  # Last 20 messages\n",
    "            recent_messages.append(entry[\"message\"])\n",
    "        return recent_messages\n",
    "    \n",
    "    def get_memory_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary of current memory state\"\"\"\n",
    "        return {\n",
    "            \"current_agent\": self.memory.current_agent,\n",
    "            \"total_messages\": len(self.memory.context_history),\n",
    "            \"agents_used\": list(self.memory.agent_interactions.keys()),\n",
    "            \"handoff_count\": self.memory.handoff_count,\n",
    "            \"session_id\": self.session_id\n",
    "        }\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        \"\"\"Clear memory for new session\"\"\"\n",
    "        self.memory = AgentMemory()\n",
    "        self.memory.current_agent = \"main_agent\"\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "\n",
    "# Example specialized agents\n",
    "class CodeAssistantAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"code_assistant\",\n",
    "            name=\"Code Assistant\",\n",
    "            description=\"Specialized in helping with programming, debugging, and code reviews\",\n",
    "            capabilities=[\"programming\", \"debugging\", \"code_review\", \"algorithm_design\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert programming assistant. You can help with:\n",
    "            - Writing and reviewing code in various languages\n",
    "            - Debugging and troubleshooting\n",
    "            - Algorithm design and optimization\n",
    "            - Best practices and code architecture\n",
    "            \n",
    "            If asked about non-programming topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "class DataAnalystAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"data_analyst\",\n",
    "            name=\"Data Analyst\",\n",
    "            description=\"Specialized in data analysis, statistics, and visualization\",\n",
    "            capabilities=[\"data_analysis\", \"statistics\", \"visualization\", \"machine_learning\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert data analyst. You can help with:\n",
    "            - Data analysis and interpretation\n",
    "            - Statistical analysis and hypothesis testing\n",
    "            - Data visualization recommendations\n",
    "            - Machine learning model suggestions\n",
    "            \n",
    "            If asked about non-data topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "class WritingAssistantAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"writing_assistant\",\n",
    "            name=\"Writing Assistant\",\n",
    "            description=\"Specialized in creative writing, editing, and content creation\",\n",
    "            capabilities=[\"creative_writing\", \"editing\", \"content_creation\", \"grammar_check\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert writing assistant. You can help with:\n",
    "            - Creative writing and storytelling\n",
    "            - Editing and proofreading\n",
    "            - Content creation for various formats\n",
    "            - Grammar and style improvements\n",
    "            \n",
    "            If asked about technical or non-writing topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the system\n",
    "    system = MultiAgentSystem(openai_api_key=\"your-openai-api-key-here\")\n",
    "    \n",
    "    # Add specialized agents\n",
    "    system.add_agent(CodeAssistantAgent())\n",
    "    system.add_agent(DataAnalystAgent())\n",
    "    system.add_agent(WritingAssistantAgent())\n",
    "    \n",
    "    # Example interaction\n",
    "    print(\"Multi-Agent System initialized!\")\n",
    "    print(\"Available agents:\")\n",
    "    for agent_id, agent in system.agents.items():\n",
    "        print(f\"- {agent.name} ({agent_id})\")\n",
    "    \n",
    "    # Example queries\n",
    "    example_queries = [\n",
    "        \"Help me write a Python function to sort a list\",\n",
    "        \"I need help analyzing my sales data\",\n",
    "        \"Can you help me write a creative story?\",\n",
    "        \"What's the weather like today?\",  # Should be handled by main agent\n",
    "    ]\n",
    "    \n",
    "    for query in example_queries:\n",
    "        print(f\"\\n--- Query: {query} ---\")\n",
    "        result = system.process_user_query(query)\n",
    "        print(f\"Agent: {result['agent_used']}\")\n",
    "        print(f\"Response: {result['response']}\")\n",
    "        print(f\"Handoffs: {result['handoff_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edefe18-96e6-44a4-85e8-7da3edec2836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Multi-Agent System initialized!\n",
      "Available agents:\n",
      "- Main Orchestrator Agent (main_agent)\n",
      "- Code Assistant (code_assistant)\n",
      "- Data Analyst (data_analyst)\n",
      "- Writing Assistant (writing_assistant)\n",
      "\n",
      "==================================================\n",
      "CONVERSATION FLOW DEMONSTRATION\n",
      "==================================================\n",
      "\n",
      "--- Step 1: User Query ---\n",
      "User: Help me write a Python function to calculate fibonacci numbers\n",
      "🤖 Currently active: Main Orchestrator Agent\n",
      "🤖 Current active agent: Main Orchestrator Agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Main Agent routing to: Code Assistant\n",
      "💭 Reasoning: The user is requesting help with writing a Python function, which falls under the capabilities of the Code Assistant, as it involves programming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Code Assistant\n",
      "🔄 Handoff occurred: Main Agent → Code Assistant\n",
      "📝 Reason: The user is requesting help with writing a Python function, which falls under the capabilities of the Code Assistant, as it involves programming.\n",
      "🤖 Response: Sure! Here's a simple Python function to calculate Fibonacci numbers using an iterative approach:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer\"\n",
      "    el...\n",
      "📊 Session info: 3 messages, Active: Code Assistant\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Step 2: User Query ---\n",
      "User: Can you optimize this for better performance?\n",
      "🤖 Currently active: Code Assistant\n",
      "🤖 Current active agent: Code Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Code Assistant\n",
      "🤖 Response: Certainly! The iterative approach is already quite efficient for calculating Fibonacci numbers. However, if you need to calculate Fibonacci numbers for very large values of `n`, you might consider usi...\n",
      "📊 Session info: 5 messages, Active: Code Assistant\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Step 3: User Query ---\n",
      "User: Now help me write a story about a programmer\n",
      "🤖 Currently active: Code Assistant\n",
      "🤖 Current active agent: Code Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Code Assistant handing off to Main Agent\n",
      "📝 Handoff reason: The query is related to creative writing, not programming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Main Agent routing to: Writing Assistant\n",
      "💭 Reasoning: The user is requesting assistance with writing a story, which falls under the capabilities of the Writing Assistant, specifically creative writing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Writing Assistant\n",
      "🔄 Handoff occurred: Main Agent → Writing Assistant\n",
      "📝 Reason: The user is requesting assistance with writing a story, which falls under the capabilities of the Writing Assistant, specifically creative writing.\n",
      "🤖 Response: **Title: The Code Whisperer**\n",
      "\n",
      "In the bustling city of Technopolis, where skyscrapers reached for the stars and neon lights painted the night, lived a young programmer named Alex. Known as \"The Code W...\n",
      "📊 Session info: 9 messages, Active: Writing Assistant\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Step 4: User Query ---\n",
      "User: Make it more dramatic and exciting\n",
      "🤖 Currently active: Writing Assistant\n",
      "🤖 Current active agent: Writing Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Writing Assistant\n",
      "🤖 Response: **Title: The Code Whisperer**\n",
      "\n",
      "In the heart of Technopolis, a city that never slept, where the pulse of technology was as constant as the heartbeat of its inhabitants, lived a young programmer named A...\n",
      "📊 Session info: 11 messages, Active: Writing Assistant\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Step 5: User Query ---\n",
      "User: What's the time complexity of the fibonacci function we discussed earlier?\n",
      "🤖 Currently active: Writing Assistant\n",
      "🤖 Current active agent: Writing Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Writing Assistant handing off to Main Agent\n",
      "📝 Handoff reason: The user is asking for technical information about time complexity, which is outside the expertise of a writing assistant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Main Agent routing to: Code Assistant\n",
      "💭 Reasoning: The query is about the time complexity of a Fibonacci function, which falls under the domain of algorithm analysis, a task suited for the Code Assistant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Code Assistant\n",
      "🔄 Handoff occurred: Main Agent → Code Assistant\n",
      "📝 Reason: The query is about the time complexity of a Fibonacci function, which falls under the domain of algorithm analysis, a task suited for the Code Assistant.\n",
      "🤖 Response: The time complexity of the Fibonacci function depends on the implementation method used.\n",
      "\n",
      "1. **Recursive Implementation**: If you are using the naive recursive approach to calculate Fibonacci numbers,...\n",
      "📊 Session info: 15 messages, Active: Code Assistant\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Step 6: User Query ---\n",
      "User: Can you analyze some sales data for me?\n",
      "🤖 Currently active: Code Assistant\n",
      "🤖 Current active agent: Code Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Code Assistant handing off to Main Agent\n",
      "📝 Handoff reason: The task involves data analysis, which may require expertise beyond programming, such as statistical or business analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Main Agent routing to: Data Analyst\n",
      "💭 Reasoning: The user is requesting an analysis of sales data, which falls under the expertise of the Data Analyst agent, who specializes in data analysis, statistics, and visualization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Agent used: Data Analyst\n",
      "🔄 Handoff occurred: Main Agent → Data Analyst\n",
      "📝 Reason: The user is requesting an analysis of sales data, which falls under the expertise of the Data Analyst agent, who specializes in data analysis, statistics, and visualization.\n",
      "🤖 Response: I can certainly help with analyzing sales data. Please provide the data set or describe the specific aspects you'd like to analyze, such as trends, patterns, or specific metrics. Additionally, let me ...\n",
      "📊 Session info: 19 messages, Active: Data Analyst\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🎉 Conversation flow demonstration complete!\n",
      "\n",
      "Key Features Demonstrated:\n",
      "✅ Direct agent-to-user interaction\n",
      "✅ Seamless handoffs between agents\n",
      "✅ Context preservation across handoffs\n",
      "✅ Intelligent routing based on query content\n",
      "✅ Agents can continue conversations in their domain\n",
      "✅ Automatic handoff when expertise is needed elsewhere\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "class AgentType(Enum):\n",
    "    MAIN = \"main\"\n",
    "    SPECIALIZED = \"specialized\"\n",
    "\n",
    "class HandoffDecision(Enum):\n",
    "    CONTINUE = \"continue\"\n",
    "    HANDOFF_TO_MAIN = \"handoff_to_main\"\n",
    "    HANDOFF_TO_AGENT = \"handoff_to_agent\"\n",
    "    DIRECT_RESPONSE = \"direct_response\"\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "    role: str\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    agent_id: Optional[str] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class AgentMemory:\n",
    "    agent_interactions: Dict[str, List[Message]] = field(default_factory=dict)\n",
    "    agent_capabilities: Dict[str, List[str]] = field(default_factory=dict)\n",
    "    context_history: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    current_agent: Optional[str] = None\n",
    "    handoff_count: int = 0\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    def __init__(self, agent_id: str, name: str, description: str, capabilities: List[str]):\n",
    "        self.agent_id = agent_id\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.capabilities = capabilities\n",
    "        self.client = openai.OpenAI()  # Initialize OpenAI client\n",
    "        \n",
    "    @abstractmethod\n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        pass\n",
    "\n",
    "class MainAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"main_agent\",\n",
    "            name=\"Main Orchestrator Agent\",\n",
    "            description=\"Main agent responsible for routing queries to appropriate specialized agents\",\n",
    "            capabilities=[\"routing\", \"orchestration\", \"context_management\", \"handoff_decision\"]\n",
    "        )\n",
    "        \n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        \"\"\"Process query and decide on agent routing\"\"\"\n",
    "        \n",
    "        # Create system prompt for main agent\n",
    "        system_prompt = f\"\"\"\n",
    "        You are the Main Orchestrator Agent in a multi-agent system. Your responsibilities:\n",
    "        1. Analyze user queries to determine which specialized agent should handle them\n",
    "        2. Maintain context across agent handoffs\n",
    "        3. Decide when to route queries to specific agents\n",
    "        4. Handle agent-to-agent communication\n",
    "        \n",
    "        Available agents and their capabilities:\n",
    "        {self._get_available_agents_info()}\n",
    "        \n",
    "        Current context: {len(context)} previous messages\n",
    "        \n",
    "        For the user query, provide a JSON response with:\n",
    "        - \"target_agent\": agent_id to route to (or \"main_agent\" to handle yourself)\n",
    "        - \"reasoning\": explanation of routing decision\n",
    "        - \"context_summary\": brief summary of relevant context\n",
    "        - \"response\": your response if handling the query yourself\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare context for LLM\n",
    "        context_messages = []\n",
    "        for msg in context[-10:]:  # Last 10 messages for context\n",
    "            context_messages.append({\n",
    "                \"role\": msg.role,\n",
    "                \"content\": f\"[{msg.agent_id}] {msg.content}\" if msg.agent_id else msg.content\n",
    "            })\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *context_messages,\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.3,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"target_agent\": \"main_agent\",\n",
    "                \"reasoning\": f\"Error in processing: {str(e)}\",\n",
    "                \"context_summary\": \"Error occurred\",\n",
    "                \"response\": \"I encountered an error processing your request. Please try again.\"\n",
    "            }\n",
    "    \n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        \"\"\"Main agent always processes queries first\"\"\"\n",
    "        return HandoffDecision.CONTINUE, None\n",
    "    \n",
    "    def _get_available_agents_info(self) -> str:\n",
    "        \"\"\"Get information about available agents\"\"\"\n",
    "        # This would be populated by the MultiAgentSystem\n",
    "        return \"This will be populated by the system with available agents\"\n",
    "\n",
    "class SpecializedAgent(BaseAgent):\n",
    "    def __init__(self, agent_id: str, name: str, description: str, capabilities: List[str], \n",
    "                 specialized_prompt: str = \"\"):\n",
    "        super().__init__(agent_id, name, description, capabilities)\n",
    "        self.specialized_prompt = specialized_prompt\n",
    "        \n",
    "    def process_query(self, query: str, context: List[Message]) -> Dict[str, Any]:\n",
    "        \"\"\"Process query with specialized knowledge\"\"\"\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        You are {self.name}: {self.description}\n",
    "        \n",
    "        Your capabilities: {', '.join(self.capabilities)}\n",
    "        \n",
    "        {self.specialized_prompt}\n",
    "        \n",
    "        Important: If the user's query is outside your expertise or they're asking for a different type of agent,\n",
    "        indicate that you should handoff back to the main agent.\n",
    "        \n",
    "        Provide a JSON response with:\n",
    "        - \"response\": your response to the user\n",
    "        - \"confidence\": confidence level (0-1) in handling this query\n",
    "        - \"should_handoff\": boolean indicating if you should handoff\n",
    "        - \"handoff_reason\": reason for handoff if applicable\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare context\n",
    "        context_messages = []\n",
    "        for msg in context[-5:]:  # Last 5 messages for context\n",
    "            context_messages.append({\n",
    "                \"role\": msg.role,\n",
    "                \"content\": msg.content\n",
    "            })\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *context_messages,\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.5,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"response\": f\"I encountered an error processing your request: {str(e)}\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"should_handoff\": True,\n",
    "                \"handoff_reason\": \"Error occurred\"\n",
    "            }\n",
    "    \n",
    "    def should_handoff(self, query: str, context: List[Message]) -> Tuple[HandoffDecision, Optional[str]]:\n",
    "        \"\"\"Determine if specialized agent should handoff\"\"\"\n",
    "        result = self.process_query(query, context)\n",
    "        \n",
    "        if result.get(\"should_handoff\", False):\n",
    "            return HandoffDecision.HANDOFF_TO_MAIN, \"main_agent\"\n",
    "        elif result.get(\"confidence\", 0) < 0.3:\n",
    "            return HandoffDecision.HANDOFF_TO_MAIN, \"main_agent\"\n",
    "        else:\n",
    "            return HandoffDecision.DIRECT_RESPONSE, None\n",
    "\n",
    "class MultiAgentSystem:\n",
    "    def __init__(self, openai_api_key: str):\n",
    "        \"\"\"Initialize the multi-agent system\"\"\"\n",
    "        openai.api_key = openai_api_key\n",
    "        \n",
    "        self.agents: Dict[str, BaseAgent] = {}\n",
    "        self.memory = AgentMemory()\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "        self.active_agent_id = None  # Track which agent is currently active\n",
    "        \n",
    "        # Initialize main agent\n",
    "        self.main_agent = MainAgent()\n",
    "        self.agents[self.main_agent.agent_id] = self.main_agent\n",
    "        self.memory.current_agent = self.main_agent.agent_id\n",
    "        self.active_agent_id = self.main_agent.agent_id\n",
    "        \n",
    "        # Update main agent with system reference\n",
    "        self.main_agent._get_available_agents_info = self._get_agents_info\n",
    "    \n",
    "    def add_agent(self, agent: BaseAgent) -> None:\n",
    "        \"\"\"Add a specialized agent to the system\"\"\"\n",
    "        self.agents[agent.agent_id] = agent\n",
    "        self.memory.agent_capabilities[agent.agent_id] = agent.capabilities\n",
    "        \n",
    "    def _get_agents_info(self) -> str:\n",
    "        \"\"\"Get formatted information about all available agents\"\"\"\n",
    "        info = []\n",
    "        for agent_id, agent in self.agents.items():\n",
    "            if agent_id != \"main_agent\":\n",
    "                info.append(f\"- {agent.name} ({agent_id}): {agent.description}\")\n",
    "                info.append(f\"  Capabilities: {', '.join(agent.capabilities)}\")\n",
    "        return \"\\n\".join(info)\n",
    "    \n",
    "    def process_user_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process user query in continuous chat session with agent handoffs\"\"\"\n",
    "        \n",
    "        # Add user message to memory\n",
    "        user_message = Message(content=query, role=\"user\")\n",
    "        self._add_message_to_memory(user_message)\n",
    "        \n",
    "        # Get current context\n",
    "        context = self._get_context_messages()\n",
    "        \n",
    "        # Use the currently active agent (could be specialized agent from previous interaction)\n",
    "        current_agent_id = self.active_agent_id\n",
    "        current_agent = self.agents[current_agent_id]\n",
    "        \n",
    "        print(f\"🤖 Current active agent: {current_agent.name}\")\n",
    "        \n",
    "        # If we're with a specialized agent, first check if it can handle the query\n",
    "        if current_agent_id != \"main_agent\":\n",
    "            # Let specialized agent try to handle the query\n",
    "            result = current_agent.process_query(query, context)\n",
    "            handoff_decision, target_agent = current_agent.should_handoff(query, context)\n",
    "            \n",
    "            if handoff_decision == HandoffDecision.DIRECT_RESPONSE:\n",
    "                # Specialized agent can handle it - direct interaction continues\n",
    "                response_message = Message(\n",
    "                    content=result.get(\"response\", \"No response provided\"),\n",
    "                    role=\"assistant\",\n",
    "                    agent_id=current_agent_id\n",
    "                )\n",
    "                self._add_message_to_memory(response_message)\n",
    "                \n",
    "                return {\n",
    "                    \"response\": result.get(\"response\", \"No response provided\"),\n",
    "                    \"agent_used\": current_agent.name,\n",
    "                    \"agent_id\": current_agent_id,\n",
    "                    \"handoff_occurred\": False,\n",
    "                    \"confidence\": result.get(\"confidence\", 1.0),\n",
    "                    \"session_id\": self.session_id,\n",
    "                    \"handoff_reason\": None\n",
    "                }\n",
    "            \n",
    "            elif handoff_decision == HandoffDecision.HANDOFF_TO_MAIN:\n",
    "                # Specialized agent wants to handoff back to main agent\n",
    "                print(f\"🔄 {current_agent.name} handing off to Main Agent\")\n",
    "                print(f\"📝 Handoff reason: {result.get('handoff_reason', 'Query outside expertise')}\")\n",
    "                \n",
    "                # Switch to main agent\n",
    "                self.active_agent_id = \"main_agent\"\n",
    "                current_agent_id = \"main_agent\"\n",
    "                current_agent = self.agents[current_agent_id]\n",
    "                \n",
    "                # Add handoff message to context\n",
    "                handoff_message = Message(\n",
    "                    content=f\"[HANDOFF] {self.agents[self.memory.current_agent].name} is handing off to Main Agent. Reason: {result.get('handoff_reason', 'Query requires different expertise')}\",\n",
    "                    role=\"system\",\n",
    "                    agent_id=\"system\"\n",
    "                )\n",
    "                self._add_message_to_memory(handoff_message)\n",
    "        \n",
    "        # Now process with main agent (either started here or handed off)\n",
    "        if current_agent_id == \"main_agent\":\n",
    "            result = current_agent.process_query(query, context)\n",
    "            target_agent_id = result.get(\"target_agent\")\n",
    "            \n",
    "            # Main agent decides routing\n",
    "            if target_agent_id and target_agent_id != \"main_agent\" and target_agent_id in self.agents:\n",
    "                # Main agent wants to handoff to specialized agent\n",
    "                print(f\"🎯 Main Agent routing to: {self.agents[target_agent_id].name}\")\n",
    "                print(f\"💭 Reasoning: {result.get('reasoning', 'Best suited for this query')}\")\n",
    "                \n",
    "                # Switch active agent\n",
    "                self.active_agent_id = target_agent_id\n",
    "                specialized_agent = self.agents[target_agent_id]\n",
    "                \n",
    "                # Add handoff message\n",
    "                handoff_message = Message(\n",
    "                    content=f\"[HANDOFF] Main Agent routing to {specialized_agent.name}. User query: {query}\",\n",
    "                    role=\"system\",\n",
    "                    agent_id=\"system\"\n",
    "                )\n",
    "                self._add_message_to_memory(handoff_message)\n",
    "                \n",
    "                # Get response from specialized agent\n",
    "                specialized_context = self._get_context_messages()\n",
    "                specialized_result = specialized_agent.process_query(query, specialized_context)\n",
    "                \n",
    "                # Store response\n",
    "                response_message = Message(\n",
    "                    content=specialized_result.get(\"response\", \"Hello! I'm now handling your request.\"),\n",
    "                    role=\"assistant\",\n",
    "                    agent_id=target_agent_id\n",
    "                )\n",
    "                self._add_message_to_memory(response_message)\n",
    "                self.memory.current_agent = target_agent_id\n",
    "                \n",
    "                return {\n",
    "                    \"response\": specialized_result.get(\"response\", \"Hello! I'm now handling your request.\"),\n",
    "                    \"agent_used\": specialized_agent.name,\n",
    "                    \"agent_id\": target_agent_id,\n",
    "                    \"handoff_occurred\": True,\n",
    "                    \"previous_agent\": \"Main Agent\",\n",
    "                    \"handoff_reason\": result.get(\"reasoning\", \"Specialized expertise needed\"),\n",
    "                    \"confidence\": specialized_result.get(\"confidence\", 1.0),\n",
    "                    \"session_id\": self.session_id\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                # Main agent handles the query itself\n",
    "                response_message = Message(\n",
    "                    content=result.get(\"response\", \"How can I help you?\"),\n",
    "                    role=\"assistant\",\n",
    "                    agent_id=current_agent_id\n",
    "                )\n",
    "                self._add_message_to_memory(response_message)\n",
    "                self.memory.current_agent = current_agent_id\n",
    "                \n",
    "                return {\n",
    "                    \"response\": result.get(\"response\", \"How can I help you?\"),\n",
    "                    \"agent_used\": current_agent.name,\n",
    "                    \"agent_id\": current_agent_id,\n",
    "                    \"handoff_occurred\": False,\n",
    "                    \"reasoning\": result.get(\"reasoning\", \"\"),\n",
    "                    \"session_id\": self.session_id\n",
    "                }\n",
    "    \n",
    "    def _add_message_to_memory(self, message: Message) -> None:\n",
    "        \"\"\"Add message to memory\"\"\"\n",
    "        if message.agent_id:\n",
    "            if message.agent_id not in self.memory.agent_interactions:\n",
    "                self.memory.agent_interactions[message.agent_id] = []\n",
    "            self.memory.agent_interactions[message.agent_id].append(message)\n",
    "        \n",
    "        # Add to context history\n",
    "        self.memory.context_history.append({\n",
    "            \"message\": message,\n",
    "            \"timestamp\": message.timestamp,\n",
    "            \"agent_id\": message.agent_id\n",
    "        })\n",
    "    \n",
    "    def _get_context_messages(self) -> List[Message]:\n",
    "        \"\"\"Get recent context messages\"\"\"\n",
    "        recent_messages = []\n",
    "        for entry in self.memory.context_history[-20:]:  # Last 20 messages\n",
    "            recent_messages.append(entry[\"message\"])\n",
    "        return recent_messages\n",
    "    \n",
    "    def get_memory_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary of current memory state\"\"\"\n",
    "        return {\n",
    "            \"current_agent\": self.memory.current_agent,\n",
    "            \"active_agent\": self.active_agent_id,\n",
    "            \"active_agent_name\": self.agents[self.active_agent_id].name if self.active_agent_id else None,\n",
    "            \"total_messages\": len(self.memory.context_history),\n",
    "            \"agents_used\": list(self.memory.agent_interactions.keys()),\n",
    "            \"handoff_count\": self.memory.handoff_count,\n",
    "            \"session_id\": self.session_id\n",
    "        }\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        \"\"\"Clear memory for new session\"\"\"\n",
    "        self.memory = AgentMemory()\n",
    "        self.memory.current_agent = \"main_agent\"\n",
    "        self.active_agent_id = \"main_agent\"\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "    \n",
    "    def get_active_agent_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get information about currently active agent\"\"\"\n",
    "        if self.active_agent_id and self.active_agent_id in self.agents:\n",
    "            agent = self.agents[self.active_agent_id]\n",
    "            return {\n",
    "                \"agent_id\": agent.agent_id,\n",
    "                \"name\": agent.name,\n",
    "                \"description\": agent.description,\n",
    "                \"capabilities\": agent.capabilities,\n",
    "                \"is_main_agent\": agent.agent_id == \"main_agent\"\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Example specialized agents\n",
    "class CodeAssistantAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"code_assistant\",\n",
    "            name=\"Code Assistant\",\n",
    "            description=\"Specialized in helping with programming, debugging, and code reviews\",\n",
    "            capabilities=[\"programming\", \"debugging\", \"code_review\", \"algorithm_design\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert programming assistant. You can help with:\n",
    "            - Writing and reviewing code in various languages\n",
    "            - Debugging and troubleshooting\n",
    "            - Algorithm design and optimization\n",
    "            - Best practices and code architecture\n",
    "            \n",
    "            If asked about non-programming topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "class DataAnalystAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"data_analyst\",\n",
    "            name=\"Data Analyst\",\n",
    "            description=\"Specialized in data analysis, statistics, and visualization\",\n",
    "            capabilities=[\"data_analysis\", \"statistics\", \"visualization\", \"machine_learning\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert data analyst. You can help with:\n",
    "            - Data analysis and interpretation\n",
    "            - Statistical analysis and hypothesis testing\n",
    "            - Data visualization recommendations\n",
    "            - Machine learning model suggestions\n",
    "            \n",
    "            If asked about non-data topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "class WritingAssistantAgent(SpecializedAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            agent_id=\"writing_assistant\",\n",
    "            name=\"Writing Assistant\",\n",
    "            description=\"Specialized in creative writing, editing, and content creation\",\n",
    "            capabilities=[\"creative_writing\", \"editing\", \"content_creation\", \"grammar_check\"],\n",
    "            specialized_prompt=\"\"\"\n",
    "            You are an expert writing assistant. You can help with:\n",
    "            - Creative writing and storytelling\n",
    "            - Editing and proofreading\n",
    "            - Content creation for various formats\n",
    "            - Grammar and style improvements\n",
    "            \n",
    "            If asked about technical or non-writing topics, suggest handoff to main agent.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "# Example usage and conversation flow demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the system\n",
    "    system = MultiAgentSystem(openai_api_key=\"your-openai-api-key-here\")\n",
    "    \n",
    "    # Add specialized agents\n",
    "    system.add_agent(CodeAssistantAgent())\n",
    "    system.add_agent(DataAnalystAgent())\n",
    "    system.add_agent(WritingAssistantAgent())\n",
    "    \n",
    "    print(\"🚀 Multi-Agent System initialized!\")\n",
    "    print(\"Available agents:\")\n",
    "    for agent_id, agent in system.agents.items():\n",
    "        print(f\"- {agent.name} ({agent_id})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CONVERSATION FLOW DEMONSTRATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Simulate a conversation flow\n",
    "    conversation_flow = [\n",
    "        \"Help me write a Python function to calculate fibonacci numbers\",  # Should route to Code Assistant\n",
    "        \"Can you optimize this for better performance?\",  # Code Assistant should continue\n",
    "        \"Now help me write a story about a programmer\",  # Code Assistant should handoff to Main Agent, then to Writing Assistant\n",
    "        \"Make it more dramatic and exciting\",  # Writing Assistant should continue\n",
    "        \"What's the time complexity of the fibonacci function we discussed earlier?\",  # Writing Assistant should handoff back to Main Agent, then to Code Assistant\n",
    "        \"Can you analyze some sales data for me?\",  # Code Assistant should handoff to Main Agent, then to Data Analyst\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(conversation_flow, 1):\n",
    "        print(f\"\\n--- Step {i}: User Query ---\")\n",
    "        print(f\"User: {query}\")\n",
    "        \n",
    "        # Get current active agent before processing\n",
    "        active_info = system.get_active_agent_info()\n",
    "        print(f\"🤖 Currently active: {active_info['name']}\")\n",
    "        \n",
    "        # Process the query\n",
    "        result = system.process_user_query(query)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"👨‍💼 Agent used: {result['agent_used']}\")\n",
    "        if result.get('handoff_occurred'):\n",
    "            print(f\"🔄 Handoff occurred: {result.get('previous_agent', 'Unknown')} → {result['agent_used']}\")\n",
    "            print(f\"📝 Reason: {result.get('handoff_reason', 'Not specified')}\")\n",
    "        \n",
    "        print(f\"🤖 Response: {result['response'][:200]}{'...' if len(result['response']) > 200 else ''}\")\n",
    "        \n",
    "        # Show memory summary\n",
    "        memory = system.get_memory_summary()\n",
    "        print(f\"📊 Session info: {memory['total_messages']} messages, Active: {memory['active_agent_name']}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n🎉 Conversation flow demonstration complete!\")\n",
    "    print(\"\\nKey Features Demonstrated:\")\n",
    "    print(\"✅ Direct agent-to-user interaction\")\n",
    "    print(\"✅ Seamless handoffs between agents\")\n",
    "    print(\"✅ Context preservation across handoffs\")\n",
    "    print(\"✅ Intelligent routing based on query content\")\n",
    "    print(\"✅ Agents can continue conversations in their domain\")\n",
    "    print(\"✅ Automatic handoff when expertise is needed elsewhere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287efd8-b39a-4b5d-ac87-2b3cc5bbbd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575259e-f660-4948-b166-8b22d7b6653e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639ec65-f71f-4177-9e3c-c6f6e5aec222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg-env",
   "language": "python",
   "name": "lg-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
